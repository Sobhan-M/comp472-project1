{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.8 - Self Exploration\n",
    "We will be experimenting with different pre-trained Word2Vec models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will reimport everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open('goemotions.json') as f:\n",
    "\tdataset = np.array(json.load(f))\n",
    "\t\n",
    "posts = dataset[:, 0]\n",
    "emotions = dataset[:, 1]\n",
    "sentiments = dataset[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Emotions.\n",
    "emotionsLabelEncoder = LabelEncoder()\n",
    "encodedEmotions = emotionsLabelEncoder.fit_transform(emotions)\n",
    "\n",
    "# Sentiments.\n",
    "sentimentsLabelEncoder = LabelEncoder()\n",
    "encodedSentiments = sentimentsLabelEncoder.fit_transform(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Loading\n",
    "In this part we will load one of the pre-trained models found [here](https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "w2v = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Extraction\n",
    "In this part we will tokenize the posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tokenizedPosts = []\n",
    "\n",
    "for post in posts:\n",
    "\ttokenizedPosts.append(nltk.tokenize.word_tokenize(post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need to find the number of tokens, let us split our training set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizedPosts_emotions_train, tokenizedPosts_emotions_test, emotions_train, emotions_test =  train_test_split(tokenizedPosts, encodedEmotions, test_size=0.20)\n",
    "tokenizedPosts_sentiments_train, tokenizedPosts_sentiments_test, sentiments_train, sentiments_test =  train_test_split(tokenizedPosts, encodedSentiments, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Computing Embeddings\n",
    "In this section we will use our Word2Vec model and our tokens to create embeddings for our posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create our general function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTokens(posts_tokenized):\n",
    "\tcounter = 0\n",
    "\tfor post in posts_tokenized:\n",
    "\t\tcounter += len(post)\n",
    "\treturn counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizedPostsToEmbedding(posts_tokenized, w2v, w2v_size=300):\n",
    "\tpostEmbeddings = []\n",
    "\n",
    "\tfor post in posts_tokenized:\n",
    "\t\t\n",
    "\t\tembedding = np.zeros(w2v_size) # We use the zero vector if none of the tokens are in our model.\n",
    "\t\t\n",
    "\t\tfor token in post:\n",
    "\t\t\tif token in w2v:\n",
    "\t\t\t\tembedding += np.array(w2v[token]) # Vector addition.\n",
    "\n",
    "\t\tembedding = embedding/len(post) # Averaging the results.\n",
    "\t\tpostEmbeddings.append(embedding)\n",
    "\n",
    "\treturn np.array(postEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use this function on our different tokenized posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddedPosts_emotions_train = tokenizedPostsToEmbedding(tokenizedPosts_emotions_train, w2v, 100)\n",
    "embeddedPosts_emotions_test= tokenizedPostsToEmbedding(tokenizedPosts_emotions_test, w2v, 100)\n",
    "embeddedPosts_sentiments_train = tokenizedPostsToEmbedding(tokenizedPosts_sentiments_train, w2v, 100)\n",
    "embeddedPosts_sentiments_test = tokenizedPostsToEmbedding(tokenizedPosts_sentiments_test, w2v, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - Hit Rates\n",
    "We will now find the hit rates of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a general function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHitRate(posts_tokenized, w2v):\n",
    "\tnumberOfHits = 0\n",
    "\tfor post in posts_tokenized:\n",
    "\t\tfor token in post:\n",
    "\t\t\tif token in w2v:\n",
    "\t\t\t\tnumberOfHits += 1\n",
    "\treturn numberOfHits / countTokens(posts_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this function to our various sets of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate Of Emotions Training Set: 0.8454672167522564\n",
      "Hit Rate Of Emotions Testing Set: 0.8451212457532424\n",
      "Hit Rate Of Sentiments Training Set: 0.8454508667897014\n",
      "Hit Rate Of Sentiments Testing Set: 0.8451843048510069\n"
     ]
    }
   ],
   "source": [
    "# Emotions Training Hit Rate.\n",
    "hitRate_emotions_train = findHitRate(tokenizedPosts_emotions_train, w2v)\n",
    "print(f\"Hit Rate Of Emotions Training Set: {hitRate_emotions_train}\")\n",
    "\n",
    "# Emotions Testing Hit Rate.\n",
    "hitRate_emotions_test = findHitRate(tokenizedPosts_emotions_test, w2v)\n",
    "print(f\"Hit Rate Of Emotions Testing Set: {hitRate_emotions_test}\")\n",
    "\n",
    "# Sentiments Training Hit Rate.\n",
    "hitRate_sentiments_train = findHitRate(tokenizedPosts_sentiments_train, w2v)\n",
    "print(f\"Hit Rate Of Sentiments Training Set: {hitRate_sentiments_train}\")\n",
    "\n",
    "# Sentiments Testing Hit Rate.\n",
    "hitRate_sentiments_test = findHitRate(tokenizedPosts_sentiments_test, w2v)\n",
    "print(f\"Hit Rate Of Sentiments Testing Set: {hitRate_sentiments_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 - Base Multi-Layered Perceptron\n",
    "We will now train and predict using our base multi-layered perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "baseMLPClassifier_emotions = MLPClassifier(early_stopping=True)\n",
    "baseMLPClassifier_sentiments = MLPClassifier(early_stopping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the emotions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37239553020602956"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseMLPClassifier_emotions.fit(embeddedPosts_emotions_train, emotions_train)\n",
    "baseMLP_emotions_results = baseMLPClassifier_emotions.predict(embeddedPosts_emotions_test)\n",
    "baseMLPClassifier_emotions.score(embeddedPosts_emotions_test, emotions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sentiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49627517169130486"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseMLPClassifier_sentiments.fit(embeddedPosts_sentiments_train, sentiments_train)\n",
    "baseMLP_sentiments_results = baseMLPClassifier_sentiments.predict(embeddedPosts_sentiments_test)\n",
    "baseMLPClassifier_sentiments.score(embeddedPosts_sentiments_test, sentiments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 - Top Multi-Layered Perceptron\n",
    "We will now use a better performing Multi-Layered Perceptron using `GridSearchCV` similar to in part 2. We will not be performing this as GridSearch takes too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# topMLPParameters = {\n",
    "#     'activation': ('logistic', 'tanh'),\n",
    "#     'hidden_layer_sizes': ((30,20), (10,10,10)),\n",
    "#     'solver': ('sgd', 'adam'),\n",
    "# \t'early_stopping': [True]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model on the emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topMLPsearch_emotions = GridSearchCV(baseMLPClassifier_emotions, topMLPParameters)\n",
    "# topMLPsearch_emotions.fit(embeddedPosts_emotions_train, emotions_train)\n",
    "# topMLP_emotions_results = topMLPsearch_emotions.predict(embeddedPosts_emotions_test)\n",
    "# topMLPsearch_emotions.score(embeddedPosts_emotions_test, emotions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform it on the sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topMLPsearch_sentiments = GridSearchCV(baseMLPClassifier_sentiments, topMLPParameters)\n",
    "# topMLPsearch_sentiments.fit(embeddedPosts_sentiments_train, sentiments_train)\n",
    "# topMLP_sentiments_results = topMLPsearch_sentiments.predict(embeddedPosts_sentiments_test)\n",
    "# topMLPsearch_sentiments.score(embeddedPosts_sentiments_test, sentiments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 - Performance Report\n",
    "We will add the new information to the `performance` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will redefine the function in part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def stringifyConfusionMatrix(confusionMatrix):\n",
    "\toutput = \"\"\n",
    "\n",
    "\tfor row in confusionMatrix:\n",
    "\t\tfor column in row:\n",
    "\t\t\toutput += f\"{column}\\t\"\n",
    "\t\toutput += \"\\n\"\n",
    "\t\n",
    "\treturn output\n",
    "\n",
    "def logPerformance(destination, title, emotionsActual, emotionsPredicted, sentimentsActual, sentimentsPredicted, emotionsPara=None, sentimentsPara=None):\n",
    "\twith open(destination, 'a') as outfile:\n",
    "\t\toutfile.write(f\"\\n# {title}\\n\")\n",
    "\t\toutfile.write(\"## Emotions:\\n\")\n",
    "\t\tif emotionsPara != None:\n",
    "\t\t\toutfile.write(\"### Parameters:\\n\")\n",
    "\t\t\toutfile.write(f\"{str(emotionsPara)}\\n\")\n",
    "\t\toutfile.write(\"### Confusion Matrix:\\n\")\n",
    "\t\toutfile.write(stringifyConfusionMatrix(metrics.confusion_matrix(emotionsActual, emotionsPredicted)))\n",
    "\t\toutfile.write(\"\\n### Metrics:\\n\")\n",
    "\t\toutfile.write(metrics.classification_report(emotionsActual, emotionsPredicted))\n",
    "\t\toutfile.write(\"## Sentiments:\\n\")\n",
    "\t\tif sentimentsPara != None:\n",
    "\t\t\toutfile.write(\"### Parameters:\\n\")\n",
    "\t\t\toutfile.write(f\"{str(sentimentsPara)}\\n\")\n",
    "\t\toutfile.write(\"### Confusion Matrix:\\n\")\n",
    "\t\toutfile.write(stringifyConfusionMatrix(metrics.confusion_matrix(sentimentsActual, sentimentsPredicted)))\n",
    "\t\toutfile.write(\"\\n### Metrics:\\n\")\n",
    "\t\toutfile.write(metrics.classification_report(sentimentsActual, sentimentsPredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will insert the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sobhan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sobhan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sobhan/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# For Base Multi-Layered Perceptron\n",
    "logPerformance(\"performance-e3.txt\", \"Embedded Base Multi-Layered Perceptron\", emotions_test, baseMLP_emotions_results, sentiments_test, baseMLP_sentiments_results)\n",
    "\n",
    "# # For Top Multi-Layered Perceptron\n",
    "# logPerformance(\"performance-e3.txt\", \"Embedded Top Multi-Layered Perceptron\", emotions_test, topMLP_emotions_results, sentiments_test, topMLP_sentiments_results, topMLPsearch_emotions.best_params_, topMLPsearch_sentiments.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 - Self Exploration\n",
    "As we can see by looking at `performance-e3.txt`, our accuracy and F1 metrics are lower than they previously were. This could be due to 2 different factors.\n",
    "\n",
    "First, it could be because of the overall lower hit-rate. In this case we had 84% hit rate. Whereas before we had 85% hit rate.\n",
    "\n",
    "The second reason could be the lower dimension of the vectors. This could provide us with less features to work with, resulting in poorer performance by our model.\n",
    "\n",
    "We can test this hypothesis by using the previous model, but with dimension 100 instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
